# TahlilchiAI - Complete Technical Implementation Guide
## AI-Powered Legal Assistance Platform for Uzbekistan

---

## üéØ EXECUTIVE SUMMARY

**Project Goal**: Build a sophisticated legal AI assistant that demonstrates technical excellence for hackathon judges while genuinely serving Uzbek citizens.

**Key Differentiators**:
1. **Advanced RAG Architecture** - Not just search, but intelligent legal reasoning
2. **Multi-Agent Orchestration** - Smart question refinement and clarification
3. **Zero-Hallucination Mode** - Every answer grounded in official legal sources
4. **Uzbek-First Design** - Native language support, not translation layer

**Timeline**: 4 weeks (MVP)  
**Team**: 5 people  
**Demo Focus**: Chat assistant with document analysis

---

## üìä SYSTEM ARCHITECTURE OVERVIEW

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         USER INTERFACE                          ‚îÇ
‚îÇ                    (Web App - Streamlit/React)                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ORCHESTRATOR AGENT                           ‚îÇ
‚îÇ  (Intent Classification, Conversation Management, Routing)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ              ‚îÇ              ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Clarifier ‚îÇ  ‚îÇ   RAG   ‚îÇ  ‚îÇ   Document  ‚îÇ
    ‚îÇ   Agent   ‚îÇ  ‚îÇ System  ‚îÇ  ‚îÇ   Analyzer  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ              ‚îÇ              ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇRetriever‚îÇ  ‚îÇ  Re-Ranker  ‚îÇ  ‚îÇ  LLM   ‚îÇ
    ‚îÇ Engine  ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇGenerator‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Vector  ‚îÇ  ‚îÇLegal Corpus ‚îÇ  ‚îÇCitation ‚îÇ
    ‚îÇ   DB    ‚îÇ  ‚îÇ  PostgreSQL ‚îÇ  ‚îÇ Engine  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üß† LLM SELECTION & STRATEGY

### Recommended LLM Setup

Based on research for Uzbek/Russian language support:

**PRIMARY LLM (Orchestrator & Generation)**:
- **GPT-4o** or **Claude Sonnet 4.5**
  - Best multilingual support including Uzbek/Russian
  - Strong reasoning capabilities
  - Low hallucination rate
  - API-based (no infrastructure needed for MVP)

**EMBEDDING MODEL**:
- **multilingual-e5-large** (Free, open-source)
  - Supports 100+ languages including Uzbek/Russian
  - 1024 dimensions
  - Good for semantic search
  - Alternative: **LaBSE** (Language-agnostic BERT)

**FALLBACK/COST OPTIMIZATION**:
- **Llama 3.1 70B** via Groq API (cheap, fast)
- **Qwen 2.5** (strong multilingual, cost-effective)

### Why NOT Translation Layer?

‚úÖ **Direct Uzbek/Russian LLM**:
- Preserves legal nuance
- No meaning loss
- Faster response
- Better cultural context

‚ùå **Translation Layer**:
- Loses legal terminology precision
- Double latency (translate ‚Üí process ‚Üí translate back)
- Potential legal misinterpretation

### Cost Estimates (Monthly - MVP)

```
Development/Testing Phase:
- GPT-4o API: ~$50-100/month (light usage)
- Claude API: ~$50-100/month
- Vector DB Hosting: $25/month (Pinecone free tier or Qdrant)
- Compute: $0 (local dev)
TOTAL: ~$100-200/month

Production (Post-Hackathon):
- LLM API: $500-2000/month (depends on users)
- Vector DB: $100-500/month
- Hosting: $100-300/month (AWS/GCP)
- Storage: $50-100/month
TOTAL: ~$750-3000/month for 1000-5000 users
```

---

## üèóÔ∏è DETAILED RAG ARCHITECTURE

### 1. Document Ingestion Pipeline

```python
# PHASE 1: Document Collection & Preprocessing

Document Sources:
‚îú‚îÄ‚îÄ Constitution of Uzbekistan
‚îú‚îÄ‚îÄ Civil Code
‚îú‚îÄ‚îÄ Criminal Code  
‚îú‚îÄ‚îÄ Administrative Code
‚îú‚îÄ‚îÄ Labor Code
‚îú‚îÄ‚îÄ Tax Code
‚îú‚îÄ‚îÄ Police Procedure Regulations
‚îî‚îÄ‚îÄ Court Precedents (if available)

Preprocessing Steps:
1. PDF Extraction ‚Üí Use PyMuPDF or Unstructured.io
2. OCR (if needed) ‚Üí Tesseract for Uzbek/Russian
3. Structure Detection ‚Üí Identify Articles, Sections, Clauses
4. Metadata Extraction ‚Üí Law type, date, article numbers
5. Text Cleaning ‚Üí Remove headers/footers, normalize spacing
```

### 2. Metadata Schema

```json
{
  "document_id": "uz_civil_code_art_123",
  "document_type": "law",
  "law_category": "civil",
  "title": "–ì—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π –∫–æ–¥–µ–∫—Å –†–µ—Å–ø—É–±–ª–∏–∫–∏ –£–∑–±–µ–∫–∏—Å—Ç–∞–Ω",
  "article_number": "123",
  "section": "–î–æ–≥–æ–≤–æ—Ä",
  "effective_date": "2024-01-01",
  "language": "russian",
  "content": "Full article text...",
  "keywords": ["contract", "agreement", "obligation"],
  "related_articles": ["124", "125", "456"],
  "jurisdiction": "uzbekistan",
  "last_updated": "2024-11-01"
}
```

### 3. Chunking Strategy

**Legal documents require special chunking**:

```python
# SMART CHUNKING RULES

1. ARTICLE-LEVEL CHUNKING (Primary):
   - Each legal article = 1 chunk
   - Preserves complete legal context
   - Includes article number in metadata

2. HIERARCHICAL CHUNKING (For long articles):
   - Split by subsections
   - Maintain parent-child relationships
   - Cross-reference related sections

3. CONTEXT WINDOWS:
   - Include previous/next article numbers
   - Add section header for context
   - Max chunk size: 512 tokens
   - Overlap: 50 tokens

Example:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Article 123: Contract Definition    ‚îÇ
‚îÇ (Parent Context: Section 5 - Civil) ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ Full article text...                ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ Related: Art. 124, 125              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 4. Embedding & Indexing

```python
# HYBRID SEARCH ARCHITECTURE

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         USER QUERY                  ‚îÇ
‚îÇ "What are my rights if fired?"     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Query Parser ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Parallel Search               ‚îÇ
    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
    ‚îÇ  ‚îÇ  Semantic   ‚îÇ   Keyword   ‚îÇ ‚îÇ
    ‚îÇ  ‚îÇ  (Vector)   ‚îÇ   (BM25)    ‚îÇ ‚îÇ
    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ             ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   FUSION RANKER                ‚îÇ
    ‚îÇ   (Reciprocal Rank Fusion)     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   RE-RANKER (Cross-Encoder)    ‚îÇ
    ‚îÇ   - Score relevance            ‚îÇ
    ‚îÇ   - Legal context matching     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   TOP K CHUNKS (K=5-10)        ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

# Vector DB Options:
1. Pinecone (managed, free tier)
2. Qdrant (open-source, can self-host)
3. Weaviate (good for legal due to filtering)

# Indexing Code Example:
from sentence_transformers import SentenceTransformer
import qdrant_client

model = SentenceTransformer('intfloat/multilingual-e5-large')
client = qdrant_client.QdrantClient(":memory:")

# Create collection
client.create_collection(
    collection_name="legal_corpus",
    vectors_config=qdrant_client.models.VectorParams(
        size=1024,  # e5-large dimension
        distance=qdrant_client.models.Distance.COSINE
    )
)

# Index documents
for doc in legal_documents:
    embedding = model.encode(doc['content'])
    client.upsert(
        collection_name="legal_corpus",
        points=[{
            "id": doc['document_id'],
            "vector": embedding,
            "payload": doc  # All metadata
        }]
    )
```

### 5. Re-Ranking System

```python
# CROSS-ENCODER RE-RANKER FOR LEGAL PRECISION

from sentence_transformers import CrossEncoder

# Use legal-tuned cross-encoder or general multilingual
reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')

def rerank_results(query, retrieved_chunks):
    """
    Re-rank retrieved chunks using cross-encoder
    
    This is CRITICAL for legal accuracy - ensures we return
    the MOST relevant law, not just semantically similar text
    """
    pairs = [[query, chunk['content']] for chunk in retrieved_chunks]
    scores = reranker.predict(pairs)
    
    # Sort by score
    ranked = sorted(
        zip(retrieved_chunks, scores),
        key=lambda x: x[1],
        reverse=True
    )
    
    return [chunk for chunk, score in ranked]

# Re-ranking reduces hallucination by 60-80% in legal RAG
```

---

## ü§ñ MULTI-AGENT ORCHESTRATION SYSTEM

This is **THE MOST IMPORTANT PART** for impressing judges. This is where you show intelligent reasoning, not just search.

### Agent Architecture

```python
"""
MULTI-AGENT SYSTEM FOR INTELLIGENT LEGAL REASONING

Agent Flow:
1. Orchestrator Agent (Router)
2. Clarifier Agent (Question Refinement)
3. Retrieval Agent (RAG System)
4. Verifier Agent (Hallucination Check)
5. Response Generator (Simple Language)
"""

class OrchestratorAgent:
    """
    Master agent that coordinates all other agents
    
    Responsibilities:
    - Classify user intent
    - Determine if clarification needed
    - Route to appropriate agent
    - Manage conversation state
    """
    
    def classify_intent(self, user_message):
        """
        Classify what the user wants
        
        Returns:
        - 'legal_query': Needs legal advice
        - 'document_analysis': Uploaded document
        - 'lawyer_needed': Complex case
        - 'general_chat': Greeting/casual
        """
        
        prompt = f"""
        Classify this user message into one category:
        
        Message: {user_message}
        
        Categories:
        - legal_query: User asking about laws, rights, procedures
        - document_analysis: User wants document reviewed
        - lawyer_needed: Case is too complex, needs real lawyer
        - general_chat: Greeting, thanks, casual conversation
        
        Also extract:
        - Legal domain: criminal, civil, administrative, tax, labor, etc.
        - Urgency: high, medium, low
        - Clarity: clear, needs_clarification
        
        Return JSON only:
        {{
          "intent": "legal_query",
          "domain": "administrative",
          "urgency": "medium",
          "clarity": "needs_clarification"
        }}
        """
        
        response = llm.generate(prompt)
        return json.loads(response)
    
    def route(self, intent_analysis, user_message, conversation_history):
        """
        Route to appropriate agent based on intent
        """
        if intent_analysis['intent'] == 'general_chat':
            return simple_response(user_message)
        
        if intent_analysis['clarity'] == 'needs_clarification':
            return ClarifierAgent().run(user_message, intent_analysis)
        
        if intent_analysis['intent'] == 'legal_query':
            return RetrievalAgent().run(user_message, intent_analysis)
        
        if intent_analysis['intent'] == 'document_analysis':
            return DocumentAnalyzerAgent().run(uploaded_doc)
        
        if intent_analysis['intent'] == 'lawyer_needed':
            return LawyerMatchingAgent().run(user_message, intent_analysis)


class ClarifierAgent:
    """
    THIS IS THE SECRET WEAPON FOR JUDGES
    
    Instead of answering immediately (and potentially hallucinating),
    this agent asks intelligent follow-up questions to get all details
    """
    
    def run(self, user_message, intent_analysis):
        """
        Generate targeted follow-up questions
        """
        
        domain = intent_analysis['domain']
        
        # Domain-specific question templates
        clarification_questions = {
            'administrative': [
                "–ì–¥–µ –≤–∞—Å –æ—Å—Ç–∞–Ω–æ–≤–∏–ª–∞ –ø–æ–ª–∏—Ü–∏—è? (Where did police stop you?)",
                "–í–∞–º –≤—ã–ø–∏—Å–∞–ª–∏ —à—Ç—Ä–∞—Ñ –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —É—Å—Ç–Ω–æ–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ? (Fine or warning?)",
                "–£ –≤–∞—Å –µ—Å—Ç—å –ø—Ä–æ—Ç–æ–∫–æ–ª –∏–ª–∏ –∫–≤–∏—Ç–∞–Ω—Ü–∏—è? (Do you have the protocol/receipt?)",
                "–ö–æ–≥–¥–∞ —ç—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ? (When did this happen?)"
            ],
            'civil': [
                "–ö–∞–∫–æ–π —Ç–∏–ø –¥–æ–≥–æ–≤–æ—Ä–∞? (What type of contract?)",
                "–ö–æ–≥–¥–∞ –±—ã–ª –ø–æ–¥–ø–∏—Å–∞–Ω –¥–æ–≥–æ–≤–æ—Ä? (When was it signed?)",
                "–ö–∞–∫–∞—è —Å—É–º–º–∞ —É–∫–∞–∑–∞–Ω–∞? (What amount is specified?)",
                "–ï—Å—Ç—å –ª–∏ –ø–∏—Å—å–º–µ–Ω–Ω—ã–π –¥–æ–≥–æ–≤–æ—Ä? (Is there a written contract?)"
            ],
            'labor': [
                "–°–∫–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã —Ä–∞–±–æ—Ç–∞–ª–∏ –≤ —ç—Ç–æ–π –∫–æ–º–ø–∞–Ω–∏–∏? (How long employed?)",
                "–ï—Å—Ç—å –ª–∏ —É –≤–∞—Å —Ç—Ä—É–¥–æ–≤–æ–π –¥–æ–≥–æ–≤–æ—Ä? (Do you have employment contract?)",
                "–ö–∞–∫–æ–≤–∞ –ø—Ä–∏—á–∏–Ω–∞ —É–≤–æ–ª—å–Ω–µ–Ω–∏—è? (What's the reason for termination?)",
                "–ü–æ–ª—É—á–∏–ª–∏ –ª–∏ –≤—ã –ø–∏—Å—å–º–µ–Ω–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ? (Did you get written notice?)"
            ]
        }
        
        # Generate 2-3 most relevant questions using LLM
        prompt = f"""
        User said: {user_message}
        Legal domain: {domain}
        
        Based on this, what are the 2-3 MOST IMPORTANT questions we need answered
        to provide accurate legal guidance?
        
        Available question templates: {clarification_questions.get(domain, [])}
        
        Generate questions that are:
        - Specific and actionable
        - In simple Uzbek or Russian
        - Help us determine exact legal situation
        
        Return JSON:
        {{
          "questions": [
            "Question 1 in user's language",
            "Question 2 in user's language"
          ],
          "reasoning": "Why these questions matter"
        }}
        """
        
        response = llm.generate(prompt)
        return json.loads(response)


class RetrievalAgent:
    """
    RAG System with Verification Layer
    """
    
    def run(self, user_message, intent_analysis):
        """
        Execute RAG pipeline with verification
        """
        # 1. Expand query with legal terms
        expanded_query = self.query_expansion(user_message, intent_analysis['domain'])
        
        # 2. Hybrid retrieval
        retrieved_chunks = self.hybrid_search(expanded_query)
        
        # 3. Re-rank for legal relevance
        reranked = self.rerank(expanded_query, retrieved_chunks)
        
        # 4. Verify retrieved content is actually relevant
        verified_chunks = self.verify_relevance(expanded_query, reranked[:5])
        
        # 5. Generate response
        if len(verified_chunks) == 0:
            return self.handle_no_legal_basis()
        
        response = self.generate_grounded_response(
            user_message, 
            verified_chunks,
            intent_analysis['domain']
        )
        
        return response
    
    def query_expansion(self, query, domain):
        """
        Expand user query with legal terminology
        
        Example:
        "I was fired" ‚Üí "—É–≤–æ–ª—å–Ω–µ–Ω–∏–µ, —Ä–∞—Å—Ç–æ—Ä–∂–µ–Ω–∏–µ —Ç—Ä—É–¥–æ–≤–æ–≥–æ –¥–æ–≥–æ–≤–æ—Ä–∞, 
                         –Ω–µ–∑–∞–∫–æ–Ω–Ω–æ–µ —É–≤–æ–ª—å–Ω–µ–Ω–∏–µ, –¢—Ä—É–¥–æ–≤–æ–π –∫–æ–¥–µ–∫—Å"
        """
        prompt = f"""
        User query: {query}
        Legal domain: {domain}
        
        Expand this query with:
        - Legal terms in Russian/Uzbek
        - Relevant code articles
        - Related legal concepts
        
        Return 3-5 search terms that will find the right laws.
        """
        return llm.generate(prompt)
    
    def verify_relevance(self, query, chunks):
        """
        CRITICAL VERIFICATION STEP
        
        Before using retrieved chunks, verify they actually answer the question
        This prevents hallucination
        """
        verified = []
        
        for chunk in chunks:
            prompt = f"""
            Question: {query}
            Legal Text: {chunk['content']}
            
            Does this legal text directly address the question?
            
            Answer ONLY 'yes' or 'no' and explain in ONE sentence.
            
            Format:
            {{
              "relevant": true/false,
              "reason": "one sentence"
            }}
            """
            
            result = llm.generate(prompt)
            verification = json.loads(result)
            
            if verification['relevant']:
                verified.append(chunk)
        
        return verified
    
    def generate_grounded_response(self, query, verified_chunks, domain):
        """
        Generate response that ONLY uses verified legal sources
        """
        
        # Combine all verified legal texts
        legal_context = "\n\n".join([
            f"[{chunk['article_number']}] {chunk['content']}"
            for chunk in verified_chunks
        ])
        
        prompt = f"""
        You are a legal assistant helping Uzbek citizens understand the law.
        
        User Question: {query}
        
        Relevant Laws:
        {legal_context}
        
        RULES:
        1. Answer ONLY based on the laws provided above
        2. Use simple Uzbek or Russian language
        3. Avoid legal jargon - explain like talking to a friend
        4. Include the article number when citing law
        5. If the law doesn't answer the question, say "I cannot find this in the law"
        
        Structure your answer:
        1. Direct answer to the question (2-3 sentences)
        2. Which law applies (mention article number)
        3. What the user should do next (practical steps)
        
        Generate answer in {'Uzbek' if 'uzb' in query else 'Russian'}:
        """
        
        answer = llm.generate(prompt)
        
        # Add citation metadata
        return {
            "answer": answer,
            "sources": [
                {
                    "article": chunk['article_number'],
                    "law": chunk['title'],
                    "text": chunk['content'][:200] + "..."
                }
                for chunk in verified_chunks
            ],
            "confidence": "high" if len(verified_chunks) >= 2 else "medium"
        }
    
    def handle_no_legal_basis(self):
        """
        What to do when we can't find relevant laws
        """
        return {
            "answer": "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–µ –º–æ–≥—É –Ω–∞–π—Ç–∏ —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–µ –£–∑–±–µ–∫–∏—Å—Ç–∞–Ω–∞. " +
                      "–†–µ–∫–æ–º–µ–Ω–¥—É—é –ø—Ä–æ–∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è —Å —é—Ä–∏—Å—Ç–æ–º –¥–ª—è –≤–∞—à–µ–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏.",
            "sources": [],
            "confidence": "none",
            "recommendation": "consult_lawyer"
        }


class DocumentAnalyzerAgent:
    """
    Analyzes uploaded contracts/documents
    """
    
    def run(self, document):
        """
        Extract risks, obligations, and unfair clauses
        """
        
        # 1. Extract text from document
        document_text = extract_text(document)
        
        # 2. Identify document type
        doc_type = self.classify_document_type(document_text)
        
        # 3. Extract key clauses
        clauses = self.extract_clauses(document_text, doc_type)
        
        # 4. Analyze each clause against legal standards
        analysis = self.analyze_clauses(clauses)
        
        # 5. Generate simplified summary
        summary = self.generate_summary(analysis)
        
        return summary
    
    def analyze_clauses(self, clauses):
        """
        Check each clause for:
        - Fairness (is it balanced?)
        - Hidden fees or penalties
        - Unreasonable obligations
        - Legal compliance
        """
        
        analyzed = []
        
        for clause in clauses:
            prompt = f"""
            Analyze this contract clause:
            
            {clause}
            
            Evaluate:
            1. Is it fair to both parties?
            2. Are there hidden costs or penalties?
            3. Are there unreasonable obligations?
            4. Does it comply with Uzbek law?
            5. Risk level: low, medium, high
            
            Return JSON:
            {{
              "fair": true/false,
              "hidden_costs": "description or null",
              "risks": ["list of risks"],
              "risk_level": "low/medium/high",
              "recommendation": "accept/negotiate/reject",
              "simple_explanation": "In simple words..."
            }}
            """
            
            analysis = llm.generate(prompt)
            analyzed.append({
                "clause": clause,
                "analysis": json.loads(analysis)
            })
        
        return analyzed
```

---

## üíæ DATABASE SCHEMA

```sql
-- PostgreSQL Schema for TahlilchiAI

-- Legal Documents Table
CREATE TABLE legal_documents (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    document_id VARCHAR(255) UNIQUE NOT NULL,
    document_type VARCHAR(50) NOT NULL, -- 'law', 'regulation', 'code'
    law_category VARCHAR(50) NOT NULL, -- 'civil', 'criminal', 'administrative', etc.
    title TEXT NOT NULL,
    article_number VARCHAR(50),
    section VARCHAR(255),
    content TEXT NOT NULL,
    effective_date DATE,
    language VARCHAR(10) NOT NULL, -- 'uz', 'ru'
    keywords TEXT[], -- Array of keywords
    related_articles TEXT[], -- Array of related article IDs
    jurisdiction VARCHAR(50) DEFAULT 'uzbekistan',
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Create indexes for fast retrieval
CREATE INDEX idx_law_category ON legal_documents(law_category);
CREATE INDEX idx_article_number ON legal_documents(article_number);
CREATE INDEX idx_keywords ON legal_documents USING GIN(keywords);

-- Conversations Table
CREATE TABLE conversations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID,
    started_at TIMESTAMP DEFAULT NOW(),
    last_message_at TIMESTAMP DEFAULT NOW(),
    conversation_state JSONB, -- Store conversation history
    intent_classification VARCHAR(100),
    legal_domain VARCHAR(50),
    resolved BOOLEAN DEFAULT FALSE
);

-- Messages Table
CREATE TABLE messages (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    conversation_id UUID REFERENCES conversations(id),
    role VARCHAR(20) NOT NULL, -- 'user', 'assistant', 'system'
    content TEXT NOT NULL,
    message_type VARCHAR(50), -- 'query', 'clarification', 'answer'
    metadata JSONB, -- Store sources, confidence, etc.
    created_at TIMESTAMP DEFAULT NOW()
);

-- Document Analysis Results
CREATE TABLE document_analyses (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID,
    document_name VARCHAR(255),
    document_type VARCHAR(100),
    analysis_result JSONB, -- Store full analysis
    risk_level VARCHAR(20),
    created_at TIMESTAMP DEFAULT NOW()
);

-- Lawyer Profiles (For Phase 2)
CREATE TABLE lawyers (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,
    specialization TEXT[],
    experience_years INTEGER,
    rating DECIMAL(3,2),
    available_for_booking BOOLEAN DEFAULT TRUE,
    profile_data JSONB
);

-- User Feedback (For improvement)
CREATE TABLE feedback (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    conversation_id UUID REFERENCES conversations(id),
    rating INTEGER CHECK (rating BETWEEN 1 AND 5),
    helpful BOOLEAN,
    feedback_text TEXT,
    created_at TIMESTAMP DEFAULT NOW()
);
```

---

## üöÄ MVP IMPLEMENTATION PLAN (4 WEEKS)

### Week 1: Foundation & Data Pipeline

**Full-Stack Lead & Backend Dev:**
- [ ] Setup project repository (GitHub)
- [ ] Initialize FastAPI backend
- [ ] Setup PostgreSQL database
- [ ] Implement document ingestion pipeline
- [ ] Create database schema
- [ ] Setup environment (Docker containers)

**NLP/ML Engineer:**
- [ ] Research and select embedding model
- [ ] Setup vector database (Qdrant/Pinecone)
- [ ] Implement chunking logic for legal documents
- [ ] Create embedding generation pipeline
- [ ] Index sample legal documents (5-10 laws)

**Frontend Dev:**
- [ ] Setup React/Streamlit project
- [ ] Design mockups for chat interface
- [ ] Implement basic UI components
- [ ] Setup routing and state management

**Product Manager:**
- [ ] Finalize demo script
- [ ] Prepare sample legal documents
- [ ] Create test queries for each legal domain
- [ ] Draft pitch presentation outline

**Deliverables:**
- ‚úÖ Working database with 5-10 laws indexed
- ‚úÖ Basic API endpoints for document retrieval
- ‚úÖ UI mockups approved

---

### Week 2: RAG System Core

**NLP/ML Engineer (PRIORITY):**
- [ ] Implement hybrid search (vector + BM25)
- [ ] Build re-ranking system
- [ ] Create query expansion logic
- [ ] Test retrieval accuracy on 50 queries
- [ ] Implement relevance verification

**Backend Dev:**
- [ ] Build RAG API endpoints
- [ ] Implement caching layer
- [ ] Create conversation state management
- [ ] Add error handling and logging

**Full-Stack Lead:**
- [ ] Integrate LLM API (GPT-4o/Claude)
- [ ] Build orchestrator agent logic
- [ ] Implement intent classification
- [ ] Create response generation pipeline

**Frontend Dev:**
- [ ] Build chat interface
- [ ] Implement message streaming
- [ ] Add loading states
- [ ] Create source citation display

**Deliverables:**
- ‚úÖ Working RAG retrieval with >70% accuracy
- ‚úÖ Functional chat interface
- ‚úÖ Intent classification working

---

### Week 3: Multi-Agent Intelligence

**Full-Stack Lead & NLP Engineer (PAIR PROGRAMMING):**
- [ ] Implement Clarifier Agent
- [ ] Build follow-up question generation
- [ ] Create domain-specific question templates
- [ ] Implement conversation memory
- [ ] Add context tracking

**Backend Dev:**
- [ ] Build document upload & analysis API
- [ ] Implement document parsing (PDF, DOCX)
- [ ] Create clause extraction logic
- [ ] Add risk analysis workflow

**Frontend Dev:**
- [ ] Design document upload interface
- [ ] Build analysis results display
- [ ] Add interactive clarification flow
- [ ] Implement source highlighting

**Product Manager & QA:**
- [ ] Test 100+ queries across all domains
- [ ] Document bugs and edge cases
- [ ] Prepare demo scenarios
- [ ] Create judge presentation slides

**Deliverables:**
- ‚úÖ Clarifier Agent fully functional
- ‚úÖ Document analyzer working
- ‚úÖ Demo-ready system

---

### Week 4: Polish, Testing & Presentation

**Everyone:**
- [ ] Bug fixing sprint
- [ ] Performance optimization
- [ ] Add Uzbek language support
- [ ] Test on slow connections
- [ ] Prepare fallback responses

**Frontend Dev:**
- [ ] UI polish and animations
- [ ] Mobile responsiveness
- [ ] Add feedback mechanism
- [ ] Error state improvements

**Product Manager:**
- [ ] Finalize pitch deck
- [ ] Rehearse demo (3x minimum)
- [ ] Prepare technical Q&A answers
- [ ] Create backup demo video

**NLP Engineer:**
- [ ] Tune retrieval thresholds
- [ ] Add more legal documents
- [ ] Optimize response time
- [ ] Document technical approach

**Deliverables:**
- ‚úÖ Polished demo-ready product
- ‚úÖ Pitch presentation ready
- ‚úÖ Technical documentation
- ‚úÖ Backup demo video

---

## üé® FRONTEND IMPLEMENTATION

### Technology Stack

**Recommended: Streamlit (MVP Speed) or React (Production Quality)**

```python
# STREAMLIT VERSION (Fastest to build)

import streamlit as st
import requests

st.set_page_config(
    page_title="TahlilchiAI",
    page_icon="‚öñÔ∏è",
    layout="wide"
)

# Session state for conversation
if 'messages' not in st.session_state:
    st.session_state.messages = []

# UI
st.title("‚öñÔ∏è TahlilchiAI - –í–∞—à —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –ø–æ–º–æ—â–Ω–∏–∫")

# Chat interface
for msg in st.session_state.messages:
    with st.chat_message(msg['role']):
        st.write(msg['content'])
        
        # Show sources if available
        if 'sources' in msg and msg['sources']:
            with st.expander("üìö –ü—Ä–∞–≤–æ–≤–∞—è –æ—Å–Ω–æ–≤–∞"):
                for source in msg['sources']:
                    st.caption(f"**{source['article']}** - {source['law']}")
                    st.text(source['text'])

# User input
if prompt := st.chat_input("–û–ø–∏—à–∏—Ç–µ –≤–∞—à—É —Å–∏—Ç—É–∞—Ü–∏—é..."):
    # Add user message
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # Call API
    with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ..."):
        response = requests.post(
            "http://localhost:8000/api/chat",
            json={
                "message": prompt,
                "conversation_history": st.session_state.messages
            }
        )
        
        result = response.json()
    
    # Add assistant response
    st.session_state.messages.append({
        "role": "assistant",
        "content": result['answer'],
        "sources": result.get('sources', [])
    })
    
    st.rerun()

# Sidebar - Document Upload
with st.sidebar:
    st.header("üìÑ –ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–≥–æ–≤–æ—Ä", type=['pdf', 'docx'])
    
    if uploaded_file:
        if st.button("–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å"):
            with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –¥–æ–∫—É–º–µ–Ω—Ç..."):
                files = {"file": uploaded_file}
                response = requests.post(
                    "http://localhost:8000/api/analyze-document",
                    files=files
                )
                
                analysis = response.json()
                st.json(analysis)
```

---

## üîß BACKEND API IMPLEMENTATION

```python
# FastAPI Backend Structure

from fastapi import FastAPI, UploadFile, File
from pydantic import BaseModel
from typing import List, Optional
import uuid

app = FastAPI(title="TahlilchiAI API")

# Models
class Message(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    message: str
    conversation_history: List[Message]
    language: str = "ru"

class ChatResponse(BaseModel):
    answer: str
    sources: List[dict]
    confidence: str
    next_action: Optional[str] = None

class ClarificationResponse(BaseModel):
    questions: List[str]
    reasoning: str

# Main Chat Endpoint
@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    Main chat endpoint - routes to orchestrator
    """
    
    # 1. Initialize orchestrator
    orchestrator = OrchestratorAgent()
    
    # 2. Classify intent
    intent = orchestrator.classify_intent(request.message)
    
    # 3. Route to appropriate agent
    if intent['clarity'] == 'needs_clarification':
        # Return clarification questions
        clarifier = ClarifierAgent()
        questions = clarifier.run(request.message, intent)
        
        return ChatResponse(
            answer="–ß—Ç–æ–±—ã –ø–æ–º–æ—á—å –≤–∞–º –ª—É—á—à–µ, –º–Ω–µ –Ω—É–∂–Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:",
            sources=[],
            confidence="pending",
            next_action="clarification",
            clarification_questions=questions['questions']
        )
    
    elif intent['intent'] == 'legal_query':
        # Execute RAG pipeline
        retrieval = RetrievalAgent()
        result = retrieval.run(request.message, intent)
        
        return ChatResponse(
            answer=result['answer'],
            sources=result['sources'],
            confidence=result['confidence']
        )
    
    elif intent['intent'] == 'lawyer_needed':
        return ChatResponse(
            answer="–í–∞—à–∞ —Å–∏—Ç—É–∞—Ü–∏—è —Ç—Ä–µ–±—É–µ—Ç –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞. " + 
                   "–Ø –º–æ–≥—É –ø–æ–º–æ—á—å –Ω–∞–π—Ç–∏ –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ —é—Ä–∏—Å—Ç–∞.",
            sources=[],
            confidence="high",
            next_action="lawyer_matching"
        )

# Document Analysis Endpoint
@app.post("/api/analyze-document")
async def analyze_document(file: UploadFile = File(...)):
    """
    Analyze uploaded legal document
    """
    
    # 1. Save file temporarily
    file_path = f"/tmp/{uuid.uuid4()}_{file.filename}"
    with open(file_path, "wb") as f:
        f.write(await file.read())
    
    # 2. Analyze
    analyzer = DocumentAnalyzerAgent()
    analysis = analyzer.run(file_path)
    
    # 3. Clean up
    os.remove(file_path)
    
    return analysis

# Retrieval Test Endpoint (for demo)
@app.post("/api/search")
async def search_legal_corpus(query: str):
    """
    Test RAG retrieval
    """
    retrieval = RetrievalAgent()
    results = retrieval.hybrid_search(query)
    
    return {"results": results}

# Health check
@app.get("/health")
async def health():
    return {"status": "healthy"}
```

---

## üìä EVALUATION & METRICS

### Key Metrics to Track

```python
# RETRIEVAL QUALITY METRICS

1. Retrieval Accuracy:
   - MRR (Mean Reciprocal Rank): >0.7
   - Precision@5: >0.8
   - Recall@10: >0.6

2. Response Quality:
   - Answer Relevance: >0.85
   - Faithfulness (grounded in sources): >0.9
   - Hallucination Rate: <5%

3. User Experience:
   - Response Time: <3 seconds
   - Clarification Rate: 20-30% (shows intelligent questioning)
   - User Satisfaction: >4/5

# EVALUATION SCRIPT
def evaluate_rag_system(test_queries, ground_truth):
    """
    Test RAG system against ground truth
    """
    
    results = {
        'correct_law_retrieved': 0,
        'answer_accurate': 0,
        'no_hallucinations': 0,
        'total': len(test_queries)
    }
    
    for query, expected in zip(test_queries, ground_truth):
        # Get response
        response = retrieval_agent.run(query, {})
        
        # Check if correct law retrieved
        retrieved_articles = [s['article'] for s in response['sources']]
        if expected['article'] in retrieved_articles:
            results['correct_law_retrieved'] += 1
        
        # Check answer accuracy (manual or LLM judge)
        if is_accurate(response['answer'], expected['answer']):
            results['answer_accurate'] += 1
        
        # Check for hallucinations
        if no_hallucinations(response['answer'], response['sources']):
            results['no_hallucinations'] += 1
    
    # Calculate metrics
    precision = results['correct_law_retrieved'] / results['total']
    accuracy = results['answer_accurate'] / results['total']
    faithfulness = results['no_hallucinations'] / results['total']
    
    return {
        'precision': precision,
        'accuracy': accuracy,
        'faithfulness': faithfulness
    }
```

---

## üé§ HACKATHON PRESENTATION STRATEGY

### Demo Script (7-10 minutes)

**Act 1: The Problem (1 min)**
- Show confusing legal document
- "Ordinary citizens don't understand their rights"
- "No one to ask, lawyers are expensive"

**Act 2: The Solution - Chat Assistant (4 min)**

**Scenario 1: Simple Query**
```
User: "–Ø –ø–æ–ª—É—á–∏–ª —à—Ç—Ä–∞—Ñ –∑–∞ –ø–∞—Ä–∫–æ–≤–∫—É. –≠—Ç–æ –∑–∞–∫–æ–Ω–Ω–æ?"
(I got a parking fine. Is this legal?)

[Show orchestrator classifying intent ‚Üí administrative law]

TahlilchiAI: "–î–∞, —à—Ç—Ä–∞—Ñ—ã –∑–∞ –Ω–∞—Ä—É—à–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª –ø–∞—Ä–∫–æ–≤–∫–∏ –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω—ã 
–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–º –∫–æ–¥–µ–∫—Å–æ–º. –°–æ–≥–ª–∞—Å–Ω–æ —Å—Ç–∞—Ç—å–µ 128..."

[Show source citation appearing]
```

**Scenario 2: Intelligent Clarification (THE WOW MOMENT)**
```
User: "–ú–µ–Ω—è —É–≤–æ–ª–∏–ª–∏ —Å —Ä–∞–±–æ—Ç—ã"
(I was fired from my job)

[Show clarifier agent activating]

TahlilchiAI: "–ß—Ç–æ–±—ã –ø–æ–º–æ—á—å –≤–∞–º, –º–Ω–µ –Ω—É–∂–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:
1. –°–∫–æ–ª—å–∫–æ –≤—ã —Ä–∞–±–æ—Ç–∞–ª–∏ –≤ –∫–æ–º–ø–∞–Ω–∏–∏?
2. –ö–∞–∫–æ–≤–∞ –ø—Ä–∏—á–∏–Ω–∞ —É–≤–æ–ª—å–Ω–µ–Ω–∏—è?
3. –ï—Å—Ç—å –ª–∏ —É –≤–∞—Å —Ç—Ä—É–¥–æ–≤–æ–π –¥–æ–≥–æ–≤–æ—Ä?"

[Show judge's reaction - "This is not a simple chatbot!"]

User: "2 –≥–æ–¥–∞, —Å–∫–∞–∑–∞–ª–∏ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ —à—Ç–∞—Ç–∞, –¥–æ–≥–æ–≤–æ—Ä –µ—Å—Ç—å"

TahlilchiAI: "–ü–æ –¢—Ä—É–¥–æ–≤–æ–º—É –∫–æ–¥–µ–∫—Å—É, –ø—Ä–∏ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–∏ —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—å 
–æ–±—è–∑–∞–Ω —É–≤–µ–¥–æ–º–∏—Ç—å –≤–∞—Å –∑–∞ 2 –º–µ—Å—è—Ü–∞ –∏ –≤—ã–ø–ª–∞—Ç–∏—Ç—å –≤—ã—Ö–æ–¥–Ω–æ–µ –ø–æ—Å–æ–±–∏–µ..."

[Show RAG retrieving exact articles]
```

**Act 3: Document Analysis (2 min)**
```
[Upload sample contract]

TahlilchiAI: 
"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Ä–∏—Å–∫–∏:
1. –í—ã—Å–æ–∫–∏–π —à—Ç—Ä–∞—Ñ –∑–∞ –¥–æ—Å—Ä–æ—á–Ω–æ–µ —Ä–∞—Å—Ç–æ—Ä–∂–µ–Ω–∏–µ (15% - –ø—Ä–µ–≤—ã—à–∞–µ—Ç –Ω–æ—Ä–º—É)
2. –°–∫—Ä—ã—Ç–∞—è –∫–æ–º–∏—Å—Å–∏—è –∑–∞ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ
3. –ù–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –ø—Ä–∞–≤–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è —É—Å–ª–æ–≤–∏–π –±–∞–Ω–∫–æ–º

–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –ü–æ–ø—Ä–æ—Å–∏—Ç–µ –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å –ø—É–Ω–∫—Ç—ã 7.2 –∏ 9.4"

[Show risk highlighting in document]
```

**Act 4: Technical Depth (2 min)**
```
[Show architecture diagram]

"Behind the scenes:
- Advanced RAG with hybrid retrieval
- Multi-agent orchestration
- Cross-encoder re-ranking
- Zero-hallucination verification
- All answers grounded in official legal sources"

[Show metrics: 85% retrieval accuracy, <2% hallucination rate]
```

**Closing:**
"TahlilchiAI - –ø–µ—Ä–≤—ã–π —à–∞–≥ –∫ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ–º—É –¥–æ—Å—Ç—É–ø—É –∫ –ø—Ä–∞–≤–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –£–∑–±–µ–∫–∏—Å—Ç–∞–Ω–µ"

---

## üõ†Ô∏è DEPLOYMENT (Post-Hackathon)

### Cloud Infrastructure

```yaml
# Docker Compose Setup

version: '3.8'

services:
  # FastAPI Backend
  api:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/tahlilchi
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - QDRANT_URL=http://qdrant:6333
    depends_on:
      - db
      - qdrant

  # PostgreSQL
  db:
    image: postgres:15
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
      - POSTGRES_DB=tahlilchi

  # Qdrant Vector DB
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
    volumes:
      - qdrant_data:/qdrant/storage

  # Streamlit Frontend
  frontend:
    build: ./frontend
    ports:
      - "8501:8501"
    depends_on:
      - api

volumes:
  postgres_data:
  qdrant_data:
```

### Cost Optimization

```python
# PRODUCTION COST REDUCTION STRATEGIES

1. Caching Layer:
   - Cache common queries (Redis)
   - Save 60-70% on LLM costs
   
2. Smaller Model for Classification:
   - Use GPT-3.5 for intent classification
   - Use GPT-4o only for final answers
   - Saves 90% on classification costs

3. Batch Processing:
   - Process document ingestion overnight
   - Reduce API rate limit costs

4. Open-Source LLM Option:
   - Deploy Llama 3.1 70B on GPU server
   - $500/month GPU vs $2000/month API calls
   - Break-even at ~100k queries/month
```

---

## üìö TECHNICAL DOCUMENTATION FOR JUDGES

### Architecture Highlights

**1. Advanced RAG Pipeline**
- Hybrid search (semantic + keyword)
- Cross-encoder re-ranking
- Multi-source verification
- Prevents hallucinations through forced grounding

**2. Multi-Agent Intelligence**
- Orchestrator for routing
- Clarifier for intelligent questioning
- Verifier for accuracy checking
- Not a simple chatbot - true reasoning system

**3. Legal-Grade Accuracy**
- Every answer cites official sources
- Relevance verification before responding
- Confidence scoring
- Fallback to lawyer recommendation when uncertain

**4. Scalable Architecture**
- Microservices design
- Horizontal scaling ready
- Caching layer for performance
- Database optimized for legal queries

---

## üîí SECURITY & PRIVACY

### Data Protection

```python
# SECURITY MEASURES

1. User Data:
   - Conversations not stored permanently (optional)
   - Document analysis temporary (deleted after 24h)
   - No PII collected without consent

2. API Security:
   - Rate limiting
   - API key authentication
   - HTTPS only
   - Input sanitization

3. Legal Corpus:
   - Version control for laws
   - Audit trail for changes
   - Source verification
   
4. Compliance:
   - GDPR-compliant (if needed)
   - Local data storage option
   - Transparent data usage
```

---

## üéØ SUCCESS CRITERIA

### MVP Success Metrics

**Technical:**
- ‚úÖ Retrieval accuracy >70%
- ‚úÖ Response time <3 seconds
- ‚úÖ Hallucination rate <5%
- ‚úÖ System uptime >95% during demo

**User Experience:**
- ‚úÖ 10 successful demo scenarios prepared
- ‚úÖ Clarification works for ambiguous queries
- ‚úÖ Simple language verified by non-lawyers
- ‚úÖ Mobile-responsive design

**Hackathon Goals:**
- ‚úÖ Judges say "This is technically impressive"
- ‚úÖ Users say "I actually understand this"
- ‚úÖ Winning pitch presentation
- ‚úÖ Working product, not just slides

---

## üìù NOVELTY POINTS FOR JUDGES

### What Makes This Special

1. **Not Just RAG - It's Intelligent**
   - Most legal chatbots just do search
   - Ours asks clarifying questions like a real lawyer
   
2. **Zero-Hallucination Architecture**
   - Forced grounding in official sources
   - Verification layer prevents made-up answers
   - Shows citations for transparency

3. **Uzbek-First Design**
   - Built for local language and laws
   - Not a translated foreign product
   - Addresses real local needs

4. **Multi-Agent System**
   - Orchestrator, clarifier, retriever, verifier
   - Shows sophisticated AI reasoning
   - Not a monolithic prompt

5. **Production-Ready Architecture**
   - Scalable microservices
   - Database optimized for legal data
   - Can handle real users post-hackathon

---

## üö® RISK MITIGATION

### Common Pitfalls & Solutions

**Problem: LLM Hallucinations**
- ‚úÖ Solution: Verification layer + forced grounding

**Problem: Slow Retrieval**
- ‚úÖ Solution: Caching + optimized indexing

**Problem: Poor Uzbek Support**
- ‚úÖ Solution: Use multilingual LLMs (GPT-4o/Claude)

**Problem: Demo Fails During Presentation**
- ‚úÖ Solution: Backup video + offline mode

**Problem: Can't Find Relevant Law**
- ‚úÖ Solution: Graceful fallback to lawyer recommendation

---

## üéì LEARNING RESOURCES

### For Team Members

**RAG Systems:**
- LangChain RAG Tutorial
- Pinecone RAG Guide
- "Building RAG from Scratch" (YouTube)

**Legal NLP:**
- Legal-BERT paper
- Harvey AI case studies
- TrueLaw blog

**Multi-Agent Systems:**
- LangGraph documentation
- CrewAI examples
- AutoGen framework

**Vector Databases:**
- Qdrant quickstart
- Pinecone Academy
- Weaviate tutorials

---

## üìû NEXT STEPS

### Immediate Actions (Day 1)

1. **Tech Lead:**
   - [ ] Create GitHub repo
   - [ ] Setup development environment
   - [ ] Choose LLM provider (GPT-4o recommended)

2. **NLP Engineer:**
   - [ ] Download 5-10 Uzbek legal documents
   - [ ] Test embedding models
   - [ ] Setup vector DB

3. **Frontend:**
   - [ ] Design chat UI mockup
   - [ ] Choose framework (Streamlit vs React)

4. **Everyone:**
   - [ ] Read this document fully
   - [ ] Schedule daily standups
   - [ ] Commit to timeline

---

## üí° FINAL THOUGHTS

### Keys to Success

1. **Focus on Chat Intelligence**
   - This is your differentiator
   - Make it work REALLY well
   - Show off the multi-agent magic

2. **Keep It Simple**
   - MVP = Core chat + basic document analysis
   - Don't build features judges won't see
   - Polish what you demo

3. **Test Relentlessly**
   - 100+ queries minimum
   - Find edge cases
   - Fix before demo day

4. **Tell a Story**
   - Not just features
   - Show how it helps real people
   - Make judges care

**You have everything you need to win. Now go build it! üöÄ**

---

## APPENDIX A: Sample Legal Documents Structure

```
legal_corpus/
‚îú‚îÄ‚îÄ civil_code/
‚îÇ   ‚îú‚îÄ‚îÄ section_1_general_provisions.txt
‚îÇ   ‚îú‚îÄ‚îÄ section_2_contracts.txt
‚îÇ   ‚îî‚îÄ‚îÄ section_3_obligations.txt
‚îú‚îÄ‚îÄ criminal_code/
‚îÇ   ‚îú‚îÄ‚îÄ general_part.txt
‚îÇ   ‚îî‚îÄ‚îÄ special_part.txt
‚îú‚îÄ‚îÄ administrative_code/
‚îÇ   ‚îú‚îÄ‚îÄ traffic_violations.txt
‚îÇ   ‚îî‚îÄ‚îÄ fines_procedures.txt
‚îî‚îÄ‚îÄ labor_code/
    ‚îú‚îÄ‚îÄ employment_contracts.txt
    ‚îî‚îÄ‚îÄ termination.txt
```

## APPENDIX B: Test Queries Database

```python
TEST_QUERIES = [
    {
        "query": "–ú–µ–Ω—è –æ—à—Ç—Ä–∞—Ñ–æ–≤–∞–ª–∏ –∑–∞ –ø–∞—Ä–∫–æ–≤–∫—É. –ó–∞–∫–æ–Ω–Ω–æ –ª–∏ —ç—Ç–æ?",
        "domain": "administrative",
        "expected_article": "128",
        "difficulty": "easy"
    },
    {
        "query": "–†–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—å —É–≤–æ–ª–∏–ª –º–µ–Ω—è –±–µ–∑ –ø—Ä–∏—á–∏–Ω—ã",
        "domain": "labor",
        "expected_article": "101",
        "needs_clarification": True,
        "difficulty": "medium"
    },
    {
        "query": "–ë–∞–Ω–∫ –∏–∑–º–µ–Ω–∏–ª –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—É—é —Å—Ç–∞–≤–∫—É –±–µ–∑ –º–æ–µ–≥–æ —Å–æ–≥–ª–∞—Å–∏—è",
        "domain": "civil",
        "expected_article": "365",
        "difficulty": "hard"
    }
    # Add 100+ more...
]
```

---

**VERSION: 1.0**  
**LAST UPDATED: November 14, 2025**  
**AUTHOR: TahlilchiAI Development Team**

